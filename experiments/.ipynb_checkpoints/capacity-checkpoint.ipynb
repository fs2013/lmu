{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.initializers import Constant, RandomUniform\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM, RNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils import multi_gpu_model\n",
    "# import tensorflow as tf; tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "import nengo\n",
    "\n",
    "from lmu import LMUCell, Legendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapacityExperiment():\n",
    "    n_gpus = 1\n",
    "    data_length_factor = 2.5\n",
    "    batch_size = 50\n",
    "    validation_split = 0.2\n",
    "\n",
    "    def data_sets(self, T):\n",
    "        n_batches = 200\n",
    "        theta = 1.0\n",
    "        dt = theta / T\n",
    "        freq = 10\n",
    "        n_outputs = 5\n",
    "        length = int(self.data_length_factor / dt + 1e-7)\n",
    "        test_split = 0.5\n",
    "        seed = 0\n",
    "        \n",
    "        rng = np.random.RandomState(seed=seed)\n",
    "        process = nengo.processes.WhiteSignal(length * dt, high=freq, y0=0)\n",
    "\n",
    "        # t = process.ntrange(length, dt=dt)\n",
    "        X = np.empty((n_batches, length, 1))  # 1 input\n",
    "        Y = np.zeros((n_batches, length, n_outputs))\n",
    "\n",
    "        delay = int(theta / dt + 1e-7)\n",
    "        assert T == delay\n",
    "        s = np.linspace(0, delay, n_outputs, dtype=int)\n",
    "\n",
    "        def _generate(x, y):\n",
    "            x[...] = process.run_steps(length, dt=dt, rng=rng)\n",
    "            x[...] /= np.max(np.abs(x))\n",
    "            for i in range(n_outputs):\n",
    "                y[s[i]:, i] = x[:-s[i], 0] if s[i] > 0 else x[:, 0]\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            _generate(X[i, :], Y[i, :])\n",
    "\n",
    "        cutoff = int(test_split*n_batches)\n",
    "\n",
    "        train_X = X[:cutoff]\n",
    "        train_Y = Y[:cutoff]\n",
    "\n",
    "        test_X = X[cutoff:]\n",
    "        test_Y = Y[cutoff:]\n",
    "\n",
    "        return s, (train_X, train_Y), (test_X, test_Y)\n",
    "\n",
    "    def make_lstm(self, units, sequence_length, output_dims):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units,\n",
    "                       input_shape=(sequence_length, 1),  # (timesteps, input_dims)\n",
    "                       return_sequences=True))  # continuously outputs per timestep\n",
    "        model.add(Dense(output_dims, activation='linear'))\n",
    "        return model\n",
    "\n",
    "    def make_lmu(self, units, sequence_length, output_dims):\n",
    "        model = Sequential()\n",
    "        model.add(RNN(\n",
    "            LMUCell(\n",
    "                units=output_dims,\n",
    "                order=units,\n",
    "                theta=sequence_length / self.data_length_factor - 0.5,  # nengolib/issues/169\n",
    "                hidden_activation='linear',\n",
    "                input_encoders_initializer=Constant(1),\n",
    "                hidden_encoders_initializer=Constant(0),\n",
    "                memory_encoders_initializer=Constant(0),\n",
    "                trainable_input_encoders=False,\n",
    "                trainable_hidden_encoders=False,\n",
    "                trainable_memory_encoders=False,\n",
    "                input_kernel_initializer=Constant(0),\n",
    "                hidden_kernel_initializer=Constant(0),\n",
    "                memory_kernel_initializer=Legendre(),\n",
    "                trainable_input_kernel=False,\n",
    "                trainable_hidden_kernel=False,\n",
    "                trainable_memory_kernel=True,\n",
    "            ),\n",
    "            input_shape=(sequence_length, 1),\n",
    "            return_sequences=True,\n",
    "        ))\n",
    "        return model\n",
    "\n",
    "    def run(self, factory, T, epochs, units=100):\n",
    "        delays, (train_X, train_Y), (test_X, test_Y) = self.data_sets(T)\n",
    "        sequence_length = train_X.shape[1]\n",
    "        output_dims = train_Y.shape[-1]\n",
    "\n",
    "        model = factory(\n",
    "            units=units,\n",
    "            sequence_length=train_X.shape[1],\n",
    "            output_dims=train_Y.shape[-1],\n",
    "        )\n",
    "        \n",
    "        if self.n_gpus > 1:\n",
    "            model = multi_gpu_model(model, gpus=self.n_gpus)\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "        model.summary()\n",
    "\n",
    "        start = time.time()\n",
    "        result = model.fit(\n",
    "            train_X, train_Y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "        \n",
    "        r = {}\n",
    "        r['time'] = (time.time() - start) / epochs if epochs > 0 else None\n",
    "        # r['model'] = model\n",
    "        # r['history'] = result\n",
    "        # r['test'] = model.evaluate(test_X, test_Y)\n",
    "        \n",
    "        hat_Y = model.predict(test_X)\n",
    "        r['mses'] = np.mean((test_Y[:, T:, :] - hat_Y[:, T:, :])**2, axis=(0, 1))\n",
    "        r['delays'] = delays\n",
    "        \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = CapacityExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LMU0 experiments with T=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvoelke/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/special/orthogonal.py:141: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.poly1d.__init__(self, poly.coeffs * float(kn))\n",
      "/home/arvoelke/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/special/orthogonal.py:1977: RuntimeWarning: overflow encountered in double_scalars\n",
      "  kn = _gam(2 * n + 1) / _gam(n + 1)**2 / 2.0**n\n",
      "/home/arvoelke/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/special/orthogonal.py:1977: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  kn = _gam(2 * n + 1) / _gam(n + 1)**2 / 2.0**n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_1 (RNN)                  (None, 250, 5)            10736     \n",
      "=================================================================\n",
      "Total params: 10,736\n",
      "Trainable params: 500\n",
      "Non-trainable params: 10,236\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Running LMU0 experiments with T=1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_2 (RNN)                  (None, 2500, 5)           10736     \n",
      "=================================================================\n",
      "Total params: 10,736\n",
      "Trainable params: 500\n",
      "Non-trainable params: 10,236\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Running LMU0 experiments with T=10000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_3 (RNN)                  (None, 25000, 5)          10736     \n",
      "=================================================================\n",
      "Total params: 10,736\n",
      "Trainable params: 500\n",
      "Non-trainable params: 10,236\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Running LMU0 experiments with T=100000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_4 (RNN)                  (None, 250000, 5)         10736     \n",
      "=================================================================\n",
      "Total params: 10,736\n",
      "Trainable params: 500\n",
      "Non-trainable params: 10,236\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n"
     ]
    }
   ],
   "source": [
    "L0 = []\n",
    "LT0 = [100, 1000, 10000, 100000]\n",
    "for T in LT0:\n",
    "    print(\"Running LMU0 experiments with T=%d\" % T)\n",
    "    L0.append(main.run(factory=main.make_lmu, T=T, epochs=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LSTM experiments with T=25\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 62, 100)           40800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 62, 5)             505       \n",
      "=================================================================\n",
      "Total params: 41,305\n",
      "Trainable params: 41,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.1237 - val_loss: 0.1255\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1226 - val_loss: 0.1243\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1215 - val_loss: 0.1232\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.1220\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1192 - val_loss: 0.1207\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1180 - val_loss: 0.1195\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1167 - val_loss: 0.1181\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1154 - val_loss: 0.1167\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 0.1153\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1125 - val_loss: 0.1140\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1112 - val_loss: 0.1128\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1100 - val_loss: 0.1118\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1092 - val_loss: 0.1108\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1083 - val_loss: 0.1096\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1070 - val_loss: 0.1083\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1057 - val_loss: 0.1071\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1046 - val_loss: 0.1060\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1036 - val_loss: 0.1047\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1023 - val_loss: 0.1033\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1011 - val_loss: 0.1020\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0999 - val_loss: 0.1007\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.0989\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0968 - val_loss: 0.0975\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0965 - val_loss: 0.0963\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0950 - val_loss: 0.0950\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0938 - val_loss: 0.0944\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.0943\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0920 - val_loss: 0.0931\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0911 - val_loss: 0.0916\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0900 - val_loss: 0.0904\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0889 - val_loss: 0.0896\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0879 - val_loss: 0.0889\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0871 - val_loss: 0.0882\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0864 - val_loss: 0.0876\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0856 - val_loss: 0.0867\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0850 - val_loss: 0.0875\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0856 - val_loss: 0.0856\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0849\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0842\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0826 - val_loss: 0.0836\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0830\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.0827\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.0823\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0805 - val_loss: 0.0820\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0815\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0812\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0807\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0790 - val_loss: 0.0802\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0798\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0795\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.0792\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0776 - val_loss: 0.0789\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0774 - val_loss: 0.0787\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0792\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0781 - val_loss: 0.0794\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0776 - val_loss: 0.0783\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0770 - val_loss: 0.0778\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.0777\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0764 - val_loss: 0.0775\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0762 - val_loss: 0.0773\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0760 - val_loss: 0.0769\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0757 - val_loss: 0.0766\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0755 - val_loss: 0.0763\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0753 - val_loss: 0.0761\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0751 - val_loss: 0.0758\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0749 - val_loss: 0.0756\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.0753\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0745 - val_loss: 0.0751\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.0749\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0743 - val_loss: 0.0747\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.0745\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0739 - val_loss: 0.0742\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0737 - val_loss: 0.0740\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0735 - val_loss: 0.0738\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0736\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0732 - val_loss: 0.0734\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0730 - val_loss: 0.0732\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0728 - val_loss: 0.0730\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0727 - val_loss: 0.0728\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0725 - val_loss: 0.0726\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0724 - val_loss: 0.0725\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0723 - val_loss: 0.0724\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0723 - val_loss: 0.0722\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0718 - val_loss: 0.0718\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0717 - val_loss: 0.0716\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0715 - val_loss: 0.0714\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0713 - val_loss: 0.0714\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0713 - val_loss: 0.0714\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0712 - val_loss: 0.0710\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0710 - val_loss: 0.0715\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0714 - val_loss: 0.0710\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.0708\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0706 - val_loss: 0.0705\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0703 - val_loss: 0.0704\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0702 - val_loss: 0.0703\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0700 - val_loss: 0.0702\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0699 - val_loss: 0.0700\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0698 - val_loss: 0.0702\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0699 - val_loss: 0.0704\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0700 - val_loss: 0.0702\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0697 - val_loss: 0.0699\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0695 - val_loss: 0.0694\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0692 - val_loss: 0.0699\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0694 - val_loss: 0.0692\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0689 - val_loss: 0.0691\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.0690\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0685 - val_loss: 0.0688\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0684 - val_loss: 0.0686\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0682 - val_loss: 0.0686\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0681 - val_loss: 0.0683\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0679 - val_loss: 0.0682\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0679 - val_loss: 0.0684\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.0702\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0698 - val_loss: 0.0681\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0678 - val_loss: 0.0685\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0675 - val_loss: 0.0678\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0674 - val_loss: 0.0676\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.0672\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.0670\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.0668\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0666 - val_loss: 0.0665\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0664 - val_loss: 0.0665\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0662\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0660 - val_loss: 0.0659\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0658 - val_loss: 0.0657\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0657 - val_loss: 0.0655\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0655 - val_loss: 0.0653\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0651\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.0650\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0651 - val_loss: 0.0647\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0649 - val_loss: 0.0645\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0642\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0646 - val_loss: 0.0640\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.0638\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.0635\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0641 - val_loss: 0.0634\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0640 - val_loss: 0.0637\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0646 - val_loss: 0.0653\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0658 - val_loss: 0.0634\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0640 - val_loss: 0.0637\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.0629\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0638 - val_loss: 0.0622\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.0621\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0632 - val_loss: 0.0623\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0632 - val_loss: 0.0620\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.0618\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0627 - val_loss: 0.0615\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0625 - val_loss: 0.0613\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0610\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.0609\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0620 - val_loss: 0.0607\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0619 - val_loss: 0.0606\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.0605\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.0603\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0615 - val_loss: 0.0602\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0613 - val_loss: 0.0602\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0613 - val_loss: 0.0599\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0610 - val_loss: 0.0597\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0608 - val_loss: 0.0596\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0607 - val_loss: 0.0595\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0606 - val_loss: 0.0593\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0604 - val_loss: 0.0593\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0604 - val_loss: 0.0591\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.0590\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0600 - val_loss: 0.0589\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0599 - val_loss: 0.0588\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0598 - val_loss: 0.0587\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0597 - val_loss: 0.0587\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0597 - val_loss: 0.0591\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0602\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0609 - val_loss: 0.0585\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0596 - val_loss: 0.0585\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0595 - val_loss: 0.0586\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0594 - val_loss: 0.0586\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0593 - val_loss: 0.0583\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0591 - val_loss: 0.0581\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0589 - val_loss: 0.0578\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0587 - val_loss: 0.0577\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.0576\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0584 - val_loss: 0.0576\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0584 - val_loss: 0.0574\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.0571\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0571\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.0571\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.0568\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0567\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0575 - val_loss: 0.0566\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.0565\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0574 - val_loss: 0.0563\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0572 - val_loss: 0.0562\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0571 - val_loss: 0.0561\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0570 - val_loss: 0.0560\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0559\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0558\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0567 - val_loss: 0.0556\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.0556\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.0557\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0568 - val_loss: 0.0557\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.0552\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.0551\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0561 - val_loss: 0.0550\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0560 - val_loss: 0.0549\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.0547\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0558 - val_loss: 0.0546\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.0546\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.0545\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.0543\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0555 - val_loss: 0.0542\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.0541\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.0540\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0538\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0551 - val_loss: 0.0538\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0551 - val_loss: 0.0540\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0544\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.0538\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0549 - val_loss: 0.0532\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.0531\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0544 - val_loss: 0.0530\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0528\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.0527\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0541 - val_loss: 0.0525\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0539 - val_loss: 0.0524\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0538 - val_loss: 0.0523\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0537 - val_loss: 0.0520\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0535 - val_loss: 0.0519\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.0518\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.0517\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0516\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.0517\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.0518\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.0512\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0526 - val_loss: 0.0509\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.0508\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0523 - val_loss: 0.0505\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0521 - val_loss: 0.0504\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0519 - val_loss: 0.0502\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0517 - val_loss: 0.0501\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0516 - val_loss: 0.0500\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0515 - val_loss: 0.0501\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0516 - val_loss: 0.0505\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0521 - val_loss: 0.0503\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0516 - val_loss: 0.0497\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0512 - val_loss: 0.0494\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.0495\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.0491\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.0489\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0503 - val_loss: 0.0490\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.0487\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.0486\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0498 - val_loss: 0.0485\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0498 - val_loss: 0.0483\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0483\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0481\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0493 - val_loss: 0.0480\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0493 - val_loss: 0.0483\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0484\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0478\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.0478\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.0477\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0487 - val_loss: 0.0474\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0475\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0472\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0482 - val_loss: 0.0473\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0470\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0469\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0478 - val_loss: 0.0468\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.0467\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0466\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0474 - val_loss: 0.0465\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0473 - val_loss: 0.0465\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0463\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.0462\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0469 - val_loss: 0.0461\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0468 - val_loss: 0.0460\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0459\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0458\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.0457\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0464 - val_loss: 0.0457\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0457\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0464 - val_loss: 0.0461\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0468 - val_loss: 0.0461\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0466 - val_loss: 0.0452\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0458 - val_loss: 0.0455\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0461 - val_loss: 0.0451\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0456 - val_loss: 0.0451\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.0447\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.0449\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0455 - val_loss: 0.0445\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0450 - val_loss: 0.0443\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0442\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0448 - val_loss: 0.0440\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0440\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0438\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0443 - val_loss: 0.0437\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0442 - val_loss: 0.0435\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0442 - val_loss: 0.0438\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0441\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0432\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0430\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0436 - val_loss: 0.0428\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.0427\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0424\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.0422\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0428 - val_loss: 0.0421\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0419\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0417\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0415\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0414\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0413\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0417\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0422\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0410\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0410\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0407\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0405\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0412 - val_loss: 0.0403\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0398\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0407 - val_loss: 0.0398\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0395\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0394\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0392\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0390\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0389\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0388\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0396 - val_loss: 0.0387\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.0385\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.0383\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.0383\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0380\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.0380\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0378\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0377\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0386 - val_loss: 0.0375\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0374\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.0376\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.0396\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0402\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.0386\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.0382\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.0376\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0386 - val_loss: 0.0370\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0381 - val_loss: 0.0370\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0381 - val_loss: 0.0367\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0377 - val_loss: 0.0364\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0364\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0374 - val_loss: 0.0364\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0373 - val_loss: 0.0362\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0371 - val_loss: 0.0363\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0371 - val_loss: 0.0361\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0370 - val_loss: 0.0358\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0367 - val_loss: 0.0356\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0354\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0364 - val_loss: 0.0353\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.0352\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0362 - val_loss: 0.0351\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0349\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0347\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0347\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0345\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0344\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0355 - val_loss: 0.0344\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.0341\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0352 - val_loss: 0.0340\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0351 - val_loss: 0.0339\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0338\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.0336\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0348 - val_loss: 0.0335\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0334\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.0332\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.0331\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0330\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0328\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0326\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0339 - val_loss: 0.0326\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0324\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.0322\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.0322\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.0321\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0319\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0332 - val_loss: 0.0318\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0330 - val_loss: 0.0316\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0314\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0328 - val_loss: 0.0315\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0319\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0332 - val_loss: 0.0313\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.0311\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0309\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.0308\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0305\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0304\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0302\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0302\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0301\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0300\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0299\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0298\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0298\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0297\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0293\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0293\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0293\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0293\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0304 - val_loss: 0.0288\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.0288\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.0287\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0283\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0283\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0280\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0278\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.0282\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0282\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0276\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0274\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0272\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0269\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0266\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0264\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0265\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0264\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0259\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0260\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0258\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0252\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0254\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0250\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0248\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0247\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0244\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0242\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0238\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0237\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0236\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.0236\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0261\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0240\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0232\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0232\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0229\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0222\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0220\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0219\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0217\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0216\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0216\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0213\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0215\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0212\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0211\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0209\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0208\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0207\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0206\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0205\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0205\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0203\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0201\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0202\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0203\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0200\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0197\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0195\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0194\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0194\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0192\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0189\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0193\n",
      "Running LSTM experiments with T=100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 250, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250, 5)            505       \n",
      "=================================================================\n",
      "Total params: 41,305\n",
      "Trainable params: 41,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.1148 - val_loss: 0.1075\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.1129 - val_loss: 0.1058\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.1112 - val_loss: 0.1044\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.1096 - val_loss: 0.1030\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.1083 - val_loss: 0.1017\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1069 - val_loss: 0.1005\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1057 - val_loss: 0.0993\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1044 - val_loss: 0.0981\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1032 - val_loss: 0.0970\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.1020 - val_loss: 0.0958\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1009 - val_loss: 0.0947\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0997 - val_loss: 0.0936\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0985 - val_loss: 0.0924\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0973 - val_loss: 0.0912\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0960 - val_loss: 0.0898\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0945 - val_loss: 0.0881\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0925 - val_loss: 0.0860\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0904 - val_loss: 0.0849\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0893 - val_loss: 0.0830\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0875 - val_loss: 0.0823\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0855 - val_loss: 0.0802\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0842 - val_loss: 0.0793\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0832 - val_loss: 0.0780\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0819 - val_loss: 0.0770\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0808 - val_loss: 0.0762\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0797 - val_loss: 0.0752\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0787 - val_loss: 0.0748\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0784 - val_loss: 0.0765\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0790 - val_loss: 0.0753\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0781 - val_loss: 0.0741\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0773 - val_loss: 0.0737\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0768 - val_loss: 0.0738\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0767 - val_loss: 0.0733\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0762 - val_loss: 0.0734\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0761 - val_loss: 0.0729\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0757 - val_loss: 0.0729\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0754 - val_loss: 0.0725\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0751 - val_loss: 0.0723\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0747 - val_loss: 0.0721\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0745 - val_loss: 0.0720\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0742 - val_loss: 0.0716\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0738 - val_loss: 0.0711\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0733 - val_loss: 0.0708\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0727 - val_loss: 0.0702\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0721 - val_loss: 0.0697\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0715 - val_loss: 0.0698\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0718 - val_loss: 0.0691\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0717 - val_loss: 0.0704\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0728 - val_loss: 0.0700\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0714 - val_loss: 0.0707\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0717 - val_loss: 0.0685\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0704 - val_loss: 0.0689\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0697 - val_loss: 0.0681\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0695 - val_loss: 0.0672\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0690 - val_loss: 0.0672\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0686 - val_loss: 0.0668\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0683 - val_loss: 0.0665\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0679 - val_loss: 0.0659\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0676 - val_loss: 0.0655\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0672 - val_loss: 0.0654\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0669 - val_loss: 0.0650\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0665 - val_loss: 0.0647\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0663 - val_loss: 0.0642\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0659 - val_loss: 0.0640\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0656 - val_loss: 0.0637\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0653 - val_loss: 0.0634\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0650 - val_loss: 0.0631\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0647 - val_loss: 0.0627\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0644 - val_loss: 0.0625\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0641 - val_loss: 0.0623\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0639 - val_loss: 0.0620\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0636 - val_loss: 0.0618\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0633 - val_loss: 0.0614\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0630 - val_loss: 0.0611\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0627 - val_loss: 0.0609\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0623 - val_loss: 0.0604\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0619 - val_loss: 0.0600\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0614 - val_loss: 0.0595\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0608 - val_loss: 0.0591\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0602 - val_loss: 0.0587\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0597 - val_loss: 0.0582\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0592 - val_loss: 0.0577\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0587 - val_loss: 0.0573\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0583 - val_loss: 0.0568\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0578 - val_loss: 0.0564\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0573 - val_loss: 0.0560\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0569 - val_loss: 0.0555\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0564 - val_loss: 0.0554\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0560 - val_loss: 0.0549\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0556 - val_loss: 0.0546\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0552 - val_loss: 0.0544\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0549 - val_loss: 0.0541\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0546 - val_loss: 0.0539\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0544 - val_loss: 0.0534\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0539 - val_loss: 0.0532\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0536 - val_loss: 0.0530\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0534 - val_loss: 0.0527\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0531 - val_loss: 0.0534\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0547 - val_loss: 0.0528\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0550 - val_loss: 0.0542\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0562 - val_loss: 0.0558\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0555 - val_loss: 0.0549\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0554 - val_loss: 0.0540\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0542 - val_loss: 0.0539\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0541 - val_loss: 0.0533\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0537 - val_loss: 0.0529\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0531 - val_loss: 0.0525\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0527 - val_loss: 0.0521\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0525 - val_loss: 0.0521\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0521 - val_loss: 0.0521\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0522 - val_loss: 0.0517\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0518 - val_loss: 0.0517\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0517 - val_loss: 0.0515\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0515 - val_loss: 0.0515\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0514 - val_loss: 0.0512\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0513 - val_loss: 0.0511\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0511 - val_loss: 0.0511\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0510 - val_loss: 0.0509\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0508 - val_loss: 0.0508\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0507 - val_loss: 0.0507\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0505 - val_loss: 0.0505\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0504 - val_loss: 0.0504\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0502 - val_loss: 0.0502\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0501 - val_loss: 0.0501\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0499 - val_loss: 0.0499\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0497 - val_loss: 0.0497\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0495 - val_loss: 0.0495\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0493 - val_loss: 0.0493\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0491 - val_loss: 0.0491\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0489 - val_loss: 0.0488\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0486 - val_loss: 0.0486\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0484 - val_loss: 0.0483\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0481 - val_loss: 0.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0479 - val_loss: 0.0479\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0475 - val_loss: 0.0474\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0472 - val_loss: 0.0472\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0470 - val_loss: 0.0470\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0468 - val_loss: 0.0467\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0465 - val_loss: 0.0464\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0462 - val_loss: 0.0462\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0460 - val_loss: 0.0458\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0456 - val_loss: 0.0455\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0454 - val_loss: 0.0453\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0451 - val_loss: 0.0451\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0450 - val_loss: 0.0465\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0498 - val_loss: 0.0470\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0480 - val_loss: 0.0487\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0483 - val_loss: 0.0476\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0474 - val_loss: 0.0478\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0477 - val_loss: 0.0474\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0474 - val_loss: 0.0465\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0465 - val_loss: 0.0462\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0464 - val_loss: 0.0462\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0463 - val_loss: 0.0459\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0460 - val_loss: 0.0455\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0456 - val_loss: 0.0456\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0455 - val_loss: 0.0454\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0453 - val_loss: 0.0451\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0450 - val_loss: 0.0448\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0448 - val_loss: 0.0446\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0446 - val_loss: 0.0445\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0444 - val_loss: 0.0442\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0441 - val_loss: 0.0441\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0440 - val_loss: 0.0439\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0435 - val_loss: 0.0434\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0433 - val_loss: 0.0431\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0431 - val_loss: 0.0430\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0429 - val_loss: 0.0429\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0427 - val_loss: 0.0426\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0423 - val_loss: 0.0421\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0421 - val_loss: 0.0420\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0419 - val_loss: 0.0419\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0417 - val_loss: 0.0418\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0417 - val_loss: 0.0416\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0415 - val_loss: 0.0416\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0414 - val_loss: 0.0413\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0412 - val_loss: 0.0413\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0410 - val_loss: 0.0411\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0409 - val_loss: 0.0409\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0407 - val_loss: 0.0408\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0407 - val_loss: 0.0407\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0406 - val_loss: 0.0406\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.0404 - val_loss: 0.0405\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0403 - val_loss: 0.0404\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0402 - val_loss: 0.0403\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0401 - val_loss: 0.0402\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0400 - val_loss: 0.0402\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0400 - val_loss: 0.0400\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0398 - val_loss: 0.0401\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0398 - val_loss: 0.0398\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0398 - val_loss: 0.0401\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0399 - val_loss: 0.0398\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0398 - val_loss: 0.0396\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0395 - val_loss: 0.0397\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0395 - val_loss: 0.0395\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0394 - val_loss: 0.0394\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0392 - val_loss: 0.0392\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0391 - val_loss: 0.0392\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0391 - val_loss: 0.0391\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0390 - val_loss: 0.0390\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0389 - val_loss: 0.0388\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0387 - val_loss: 0.0386\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0386 - val_loss: 0.0386\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0385 - val_loss: 0.0386\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0385 - val_loss: 0.0383\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0384 - val_loss: 0.0382\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0381 - val_loss: 0.0380\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0381 - val_loss: 0.0379\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0380 - val_loss: 0.0377\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0378 - val_loss: 0.0375\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0377 - val_loss: 0.0375\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0376 - val_loss: 0.0374\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0371 - val_loss: 0.0369\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0373 - val_loss: 0.0368\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0370 - val_loss: 0.0364\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0367 - val_loss: 0.0361\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0368 - val_loss: 0.0359\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0365 - val_loss: 0.0357\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0362 - val_loss: 0.0358\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0363 - val_loss: 0.0358\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0362 - val_loss: 0.0352\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0364 - val_loss: 0.0358\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0363 - val_loss: 0.0350\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0359 - val_loss: 0.0347\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0355 - val_loss: 0.0348\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0354 - val_loss: 0.0343\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0352 - val_loss: 0.0340\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0349 - val_loss: 0.0339\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0347 - val_loss: 0.0335\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0345 - val_loss: 0.0333\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0343 - val_loss: 0.0332\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0342 - val_loss: 0.0330\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0340 - val_loss: 0.0328\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0338 - val_loss: 0.0327\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0337 - val_loss: 0.0325\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0335 - val_loss: 0.0323\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0333 - val_loss: 0.0321\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0332 - val_loss: 0.0319\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0330 - val_loss: 0.0318\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0328 - val_loss: 0.0316\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0327 - val_loss: 0.0315\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0325 - val_loss: 0.0313\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0323 - val_loss: 0.0311\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0322 - val_loss: 0.0310\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0320 - val_loss: 0.0309\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0319 - val_loss: 0.0307\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0317 - val_loss: 0.0305\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0316 - val_loss: 0.0304\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0314 - val_loss: 0.0304\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0313 - val_loss: 0.0301\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0312 - val_loss: 0.0302\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.0311 - val_loss: 0.0299\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0309 - val_loss: 0.0297\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0307 - val_loss: 0.0297\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0306 - val_loss: 0.0296\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0306 - val_loss: 0.0294\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0304 - val_loss: 0.0296\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0304 - val_loss: 0.0297\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0306 - val_loss: 0.0292\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0304 - val_loss: 0.0307\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0313 - val_loss: 0.0316\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0329 - val_loss: 0.0308\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0322 - val_loss: 0.0323\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0327 - val_loss: 0.0315\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0315 - val_loss: 0.0305\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0315 - val_loss: 0.0307\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0310 - val_loss: 0.0297\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0305 - val_loss: 0.0297\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0302 - val_loss: 0.0292\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0301 - val_loss: 0.0291\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0297 - val_loss: 0.0289\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0297 - val_loss: 0.0288\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0296 - val_loss: 0.0286\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0294 - val_loss: 0.0285\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0293 - val_loss: 0.0287\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0293 - val_loss: 0.0284\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0291 - val_loss: 0.0282\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0290 - val_loss: 0.0282\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0289 - val_loss: 0.0282\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0288 - val_loss: 0.0280\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0287 - val_loss: 0.0279\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0286 - val_loss: 0.0278\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0285 - val_loss: 0.0278\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0284 - val_loss: 0.0277\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0281 - val_loss: 0.0274\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0281 - val_loss: 0.0273\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0273\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0272\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0272\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0279 - val_loss: 0.0271\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0278 - val_loss: 0.0270\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0266\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0273 - val_loss: 0.0266\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0265\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0273 - val_loss: 0.0265\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0272 - val_loss: 0.0264\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0271 - val_loss: 0.0263\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0270 - val_loss: 0.0261\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0261\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0269 - val_loss: 0.0260\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0267 - val_loss: 0.0259\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0267 - val_loss: 0.0258\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0266 - val_loss: 0.0257\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0266 - val_loss: 0.0258\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0266 - val_loss: 0.0256\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0266 - val_loss: 0.0255\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0264 - val_loss: 0.0259\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0268 - val_loss: 0.0264\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0280 - val_loss: 0.0265\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0262\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0271 - val_loss: 0.0263\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0268 - val_loss: 0.0263\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0270 - val_loss: 0.0259\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0266 - val_loss: 0.0254\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0264 - val_loss: 0.0250\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0262 - val_loss: 0.0251\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0250\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0250\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0259 - val_loss: 0.0248\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0258 - val_loss: 0.0246\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0257 - val_loss: 0.0245\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0255 - val_loss: 0.0244\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0254 - val_loss: 0.0243\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0254 - val_loss: 0.0243\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0253 - val_loss: 0.0242\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0242\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0252 - val_loss: 0.0241\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0251 - val_loss: 0.0240\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0250 - val_loss: 0.0239\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0250 - val_loss: 0.0239\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0249 - val_loss: 0.0238\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0249 - val_loss: 0.0237\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0248 - val_loss: 0.0237\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0247 - val_loss: 0.0236\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0247 - val_loss: 0.0236\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0246 - val_loss: 0.0235\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0245 - val_loss: 0.0234\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0245 - val_loss: 0.0233\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0244 - val_loss: 0.0233\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0244 - val_loss: 0.0232\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0242 - val_loss: 0.0231\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0242 - val_loss: 0.0230\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0241 - val_loss: 0.0230\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0240 - val_loss: 0.0229\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0240 - val_loss: 0.0228\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0239 - val_loss: 0.0227\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0236 - val_loss: 0.0224\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0235 - val_loss: 0.0224\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0235 - val_loss: 0.0223\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0234 - val_loss: 0.0222\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0233 - val_loss: 0.0222\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0233 - val_loss: 0.0221\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0232 - val_loss: 0.0220\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0231 - val_loss: 0.0219\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0230 - val_loss: 0.0219\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0229 - val_loss: 0.0217\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0228 - val_loss: 0.0217\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0228 - val_loss: 0.0216\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0227 - val_loss: 0.0215\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0226 - val_loss: 0.0214\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0225 - val_loss: 0.0213\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0224 - val_loss: 0.0213\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0224 - val_loss: 0.0212\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0223 - val_loss: 0.0211\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0222 - val_loss: 0.0211\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0222 - val_loss: 0.0211\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0222 - val_loss: 0.0212\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0222 - val_loss: 0.0209\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0220 - val_loss: 0.0209\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0220 - val_loss: 0.0207\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0218 - val_loss: 0.0209\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0221 - val_loss: 0.0206\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0218 - val_loss: 0.0213\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0221 - val_loss: 0.0210\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0223 - val_loss: 0.0205\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0218 - val_loss: 0.0210\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0226 - val_loss: 0.0214\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0222 - val_loss: 0.0211\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0221 - val_loss: 0.0210\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0218 - val_loss: 0.0207\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0217 - val_loss: 0.0203\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0215 - val_loss: 0.0203\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0213 - val_loss: 0.0203\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0210 - val_loss: 0.0198\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0209 - val_loss: 0.0197\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0208 - val_loss: 0.0197\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0206 - val_loss: 0.0196\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0206 - val_loss: 0.0195\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0205 - val_loss: 0.0195\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0205 - val_loss: 0.0194\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0203 - val_loss: 0.0192\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0201 - val_loss: 0.0190\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0200 - val_loss: 0.0190\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0199 - val_loss: 0.0188\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0197 - val_loss: 0.0188\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0197 - val_loss: 0.0187\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0197 - val_loss: 0.0188\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0197 - val_loss: 0.0188\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0200 - val_loss: 0.0190\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0202 - val_loss: 0.0185\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0200 - val_loss: 0.0216\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0221 - val_loss: 0.0244\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0246 - val_loss: 0.0249\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0244 - val_loss: 0.0275\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0269 - val_loss: 0.0243\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0248 - val_loss: 0.0236\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0245 - val_loss: 0.0219\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0223 - val_loss: 0.0199\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0213 - val_loss: 0.0198\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0207 - val_loss: 0.0193\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0199 - val_loss: 0.0188\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.0197 - val_loss: 0.0188\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0196 - val_loss: 0.0186\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0195 - val_loss: 0.0185\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0194 - val_loss: 0.0183\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0193 - val_loss: 0.0183\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0192 - val_loss: 0.0181\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0189 - val_loss: 0.0180\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0187 - val_loss: 0.0178\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.0187 - val_loss: 0.0177\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0185 - val_loss: 0.0176\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0183 - val_loss: 0.0174\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0183 - val_loss: 0.0174\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0182 - val_loss: 0.0173\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.0182 - val_loss: 0.0173\n",
      "Running LSTM experiments with T=400\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1000, 100)         40800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000, 5)           505       \n",
      "=================================================================\n",
      "Total params: 41,305\n",
      "Trainable params: 41,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.1111 - val_loss: 0.1128\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.1048 - val_loss: 0.1070\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0994 - val_loss: 0.1022\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0950 - val_loss: 0.0985\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0918 - val_loss: 0.0960\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0896 - val_loss: 0.0946\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0884 - val_loss: 0.0932\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0871 - val_loss: 0.0918\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0858 - val_loss: 0.0905\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0848 - val_loss: 0.0896\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0841 - val_loss: 0.0890\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0836 - val_loss: 0.0885\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0831 - val_loss: 0.0880\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0827 - val_loss: 0.0876\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0823 - val_loss: 0.0873\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0820 - val_loss: 0.0871\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0819 - val_loss: 0.0871\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0819 - val_loss: 0.0871\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0818 - val_loss: 0.0870\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0818 - val_loss: 0.0870\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0817 - val_loss: 0.0869\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0817 - val_loss: 0.0868\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0816 - val_loss: 0.0867\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0816 - val_loss: 0.0866\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0815 - val_loss: 0.0866\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0815 - val_loss: 0.0866\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0815 - val_loss: 0.0866\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0815 - val_loss: 0.0867\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0815 - val_loss: 0.0867\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0814 - val_loss: 0.0866\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0814 - val_loss: 0.0866\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0814 - val_loss: 0.0866\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0814 - val_loss: 0.0865\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0812 - val_loss: 0.0863\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0811 - val_loss: 0.0864\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0811 - val_loss: 0.0864\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0811 - val_loss: 0.0864\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0811 - val_loss: 0.0864\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0811 - val_loss: 0.0864\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0810 - val_loss: 0.0863\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0810 - val_loss: 0.0863\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0810 - val_loss: 0.0863\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0810 - val_loss: 0.0861\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0809 - val_loss: 0.0860\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0808 - val_loss: 0.0859\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0807 - val_loss: 0.0858\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0806 - val_loss: 0.0855\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0804 - val_loss: 0.0849\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0798 - val_loss: 0.0834\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0784 - val_loss: 0.0825\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0779 - val_loss: 0.0811\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0770 - val_loss: 0.0817\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0767 - val_loss: 0.0812\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.0767 - val_loss: 0.0820\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0764 - val_loss: 0.0891\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0827 - val_loss: 0.0851\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0801 - val_loss: 0.0863\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0810 - val_loss: 0.0866\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0812 - val_loss: 0.0867\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0813 - val_loss: 0.0867\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0813 - val_loss: 0.0866\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 0.0813 - val_loss: 0.0865\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0813 - val_loss: 0.0864\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0812 - val_loss: 0.0863\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0812 - val_loss: 0.0863\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0812 - val_loss: 0.0863\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0811 - val_loss: 0.0863\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0811 - val_loss: 0.0862\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0811 - val_loss: 0.0862\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0810 - val_loss: 0.0862\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0810 - val_loss: 0.0861\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0810 - val_loss: 0.0861\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0809 - val_loss: 0.0860\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 3s 44ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0808 - val_loss: 0.0859\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0808 - val_loss: 0.0859\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0807 - val_loss: 0.0859\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0807 - val_loss: 0.0859\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0807 - val_loss: 0.0859\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0807 - val_loss: 0.0859\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0807 - val_loss: 0.0859\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0807 - val_loss: 0.0858\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0807 - val_loss: 0.0858\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0806 - val_loss: 0.0858\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0806 - val_loss: 0.0857\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0806 - val_loss: 0.0857\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0806 - val_loss: 0.0857\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0805 - val_loss: 0.0857\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0805 - val_loss: 0.0856\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0805 - val_loss: 0.0856\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0804 - val_loss: 0.0855\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0804 - val_loss: 0.0854\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0804 - val_loss: 0.0854\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0803 - val_loss: 0.0853\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0802 - val_loss: 0.0852\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0801 - val_loss: 0.0850\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0800 - val_loss: 0.0849\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0799 - val_loss: 0.0846\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0796 - val_loss: 0.0843\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0793 - val_loss: 0.0837\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0788 - val_loss: 0.0828\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0781 - val_loss: 0.0818\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0775 - val_loss: 0.0812\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0770 - val_loss: 0.0810\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0766 - val_loss: 0.0802\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0759 - val_loss: 0.0802\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0756 - val_loss: 0.0802\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0750 - val_loss: 0.0803\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0754 - val_loss: 0.0796\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0747 - val_loss: 0.0809\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0757 - val_loss: 0.0800\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0753 - val_loss: 0.0812\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0762 - val_loss: 0.0820\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0760 - val_loss: 0.0815\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0765 - val_loss: 0.0808\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0755 - val_loss: 0.0800\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0750 - val_loss: 0.0798\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0746 - val_loss: 0.0798\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 3s 31ms/step - loss: 0.0748 - val_loss: 0.0794\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0745 - val_loss: 0.0791\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0744 - val_loss: 0.0791\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0742 - val_loss: 0.0792\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0743 - val_loss: 0.0791\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0742 - val_loss: 0.0788\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0740 - val_loss: 0.0788\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0739 - val_loss: 0.0789\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0740 - val_loss: 0.0792\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0740 - val_loss: 0.0789\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0739 - val_loss: 0.0790\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0740 - val_loss: 0.0788\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0739 - val_loss: 0.0787\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0738 - val_loss: 0.0788\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0737 - val_loss: 0.0787\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0737 - val_loss: 0.0787\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0736 - val_loss: 0.0788\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0736 - val_loss: 0.0788\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0737 - val_loss: 0.0788\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0736 - val_loss: 0.0789\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0736 - val_loss: 0.0787\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0735 - val_loss: 0.0788\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0735 - val_loss: 0.0788\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0735 - val_loss: 0.0791\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0738 - val_loss: 0.0792\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0738 - val_loss: 0.0789\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0736 - val_loss: 0.0787\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.0735 - val_loss: 0.0787\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0735 - val_loss: 0.0789\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0736 - val_loss: 0.0788\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0734 - val_loss: 0.0788\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0734 - val_loss: 0.0791\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0738 - val_loss: 0.0790\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0736 - val_loss: 0.0789\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0735 - val_loss: 0.0787\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0736 - val_loss: 0.0791\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0737 - val_loss: 0.0790\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0736 - val_loss: 0.0787\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0735 - val_loss: 0.0790\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0735 - val_loss: 0.0787\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0734 - val_loss: 0.0787\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0733 - val_loss: 0.0786\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0733 - val_loss: 0.0786\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0734 - val_loss: 0.0787\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0733 - val_loss: 0.0786\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0733 - val_loss: 0.0785\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0732 - val_loss: 0.0786\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0732 - val_loss: 0.0786\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0732 - val_loss: 0.0786\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0732 - val_loss: 0.0785\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0731 - val_loss: 0.0785\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0731 - val_loss: 0.0785\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0730 - val_loss: 0.0785\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0730 - val_loss: 0.0785\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0730 - val_loss: 0.0786\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0731 - val_loss: 0.0785\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0731 - val_loss: 0.0785\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0730 - val_loss: 0.0785\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0730 - val_loss: 0.0784\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0730 - val_loss: 0.0784\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0729 - val_loss: 0.0785\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0728 - val_loss: 0.0783\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0728 - val_loss: 0.0782\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0728 - val_loss: 0.0782\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0728 - val_loss: 0.0782\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0728 - val_loss: 0.0782\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0728 - val_loss: 0.0782\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0728 - val_loss: 0.0781\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0727 - val_loss: 0.0781\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0727 - val_loss: 0.0783\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.0729 - val_loss: 0.0780\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0728 - val_loss: 0.0780\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0727 - val_loss: 0.0784\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0729 - val_loss: 0.0783\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0731 - val_loss: 0.0782\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0732 - val_loss: 0.0788\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0735 - val_loss: 0.0780\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0730 - val_loss: 0.0792\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0741 - val_loss: 0.0778\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0735 - val_loss: 0.0787\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0743 - val_loss: 0.0794\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0740 - val_loss: 0.0795\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0738 - val_loss: 0.0781\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0732 - val_loss: 0.0777\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0728 - val_loss: 0.0774\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0726 - val_loss: 0.0777\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0728 - val_loss: 0.0770\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0722 - val_loss: 0.0770\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0722 - val_loss: 0.0770\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0720 - val_loss: 0.0767\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0718 - val_loss: 0.0764\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0716 - val_loss: 0.0763\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0714 - val_loss: 0.0760\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0713 - val_loss: 0.0757\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0710 - val_loss: 0.0754\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0708 - val_loss: 0.0750\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0705 - val_loss: 0.0746\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0702 - val_loss: 0.0741\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0698 - val_loss: 0.0737\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0696 - val_loss: 0.0733\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0693 - val_loss: 0.0731\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0692 - val_loss: 0.0735\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0695 - val_loss: 0.0735\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0695 - val_loss: 0.0754\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0713 - val_loss: 0.0758\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0715 - val_loss: 0.0756\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0713 - val_loss: 0.0745\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.0703 - val_loss: 0.0754\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0716 - val_loss: 0.0765\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0725 - val_loss: 0.0773\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0730 - val_loss: 0.0775\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0731 - val_loss: 0.0760\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0722 - val_loss: 0.0740\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0699 - val_loss: 0.0741\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0703 - val_loss: 0.0747\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0702 - val_loss: 0.0724\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0692 - val_loss: 0.0725\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 2s 31ms/step - loss: 0.0690 - val_loss: 0.0726\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0686 - val_loss: 0.0722\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0685 - val_loss: 0.0735\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0696 - val_loss: 0.0745\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0707 - val_loss: 0.0738\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.0697 - val_loss: 0.0731\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0694 - val_loss: 0.0726\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0685 - val_loss: 0.0724\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0685 - val_loss: 0.0723\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0686 - val_loss: 0.0715\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0677 - val_loss: 0.0713\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0679 - val_loss: 0.0712\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0676 - val_loss: 0.0711\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0675 - val_loss: 0.0730\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0693 - val_loss: 0.0746\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0705 - val_loss: 0.0729\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0690 - val_loss: 0.0726\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0691 - val_loss: 0.0719\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0685 - val_loss: 0.0715\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0682 - val_loss: 0.0716\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0686 - val_loss: 0.0718\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0683 - val_loss: 0.0720\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 3s 31ms/step - loss: 0.0681 - val_loss: 0.0722\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0681 - val_loss: 0.0714\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0679 - val_loss: 0.0710\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0677 - val_loss: 0.0714\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0677 - val_loss: 0.0713\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0675 - val_loss: 0.0707\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0674 - val_loss: 0.0707\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0672 - val_loss: 0.0705\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0670 - val_loss: 0.0702\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0669 - val_loss: 0.0707\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0671 - val_loss: 0.0708\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0671 - val_loss: 0.0709\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0672 - val_loss: 0.0704\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0669 - val_loss: 0.0705\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0669 - val_loss: 0.0704\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0668 - val_loss: 0.0705\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0669 - val_loss: 0.0702\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0667 - val_loss: 0.0706\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0669 - val_loss: 0.0705\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 0.0668 - val_loss: 0.0704\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0668 - val_loss: 0.0699\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0666 - val_loss: 0.0698\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0665 - val_loss: 0.0699\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0667 - val_loss: 0.0701\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 3s 31ms/step - loss: 0.0665 - val_loss: 0.0697\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0664 - val_loss: 0.0698\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0663 - val_loss: 0.0696\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0663 - val_loss: 0.0698\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0663 - val_loss: 0.0695\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0662 - val_loss: 0.0699\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.0663 - val_loss: 0.0695\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0663 - val_loss: 0.0697\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0663 - val_loss: 0.0697\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0662 - val_loss: 0.0696\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0662 - val_loss: 0.0695\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0662 - val_loss: 0.0696\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0662 - val_loss: 0.0695\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0663 - val_loss: 0.0700\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0663 - val_loss: 0.0692\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.0661 - val_loss: 0.0694\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0661 - val_loss: 0.0695\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 5s 65ms/step - loss: 0.0660 - val_loss: 0.0692\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0660 - val_loss: 0.0695\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0661 - val_loss: 0.0692\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0660 - val_loss: 0.0691\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0659 - val_loss: 0.0691\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0659 - val_loss: 0.0693\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0660 - val_loss: 0.0694\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0659 - val_loss: 0.0691\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0660 - val_loss: 0.0691\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0659 - val_loss: 0.0693\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0659 - val_loss: 0.0692\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0660 - val_loss: 0.0694\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0661 - val_loss: 0.0692\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0660 - val_loss: 0.0691\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0658 - val_loss: 0.0693\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0659 - val_loss: 0.0690\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0659 - val_loss: 0.0695\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.0659 - val_loss: 0.0689\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0658 - val_loss: 0.0690\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0658 - val_loss: 0.0690\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0658 - val_loss: 0.0692\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0660 - val_loss: 0.0694\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0659 - val_loss: 0.0689\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0658 - val_loss: 0.0689\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0657 - val_loss: 0.0688\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0656 - val_loss: 0.0687\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0656 - val_loss: 0.0690\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0656 - val_loss: 0.0686\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0655 - val_loss: 0.0687\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0654 - val_loss: 0.0686\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0654 - val_loss: 0.0686\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0654 - val_loss: 0.0685\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0654 - val_loss: 0.0686\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0655 - val_loss: 0.0689\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.0655 - val_loss: 0.0684\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0653 - val_loss: 0.0685\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0652 - val_loss: 0.0683\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0653 - val_loss: 0.0683\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0652 - val_loss: 0.0683\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0652 - val_loss: 0.0684\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0652 - val_loss: 0.0685\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0652 - val_loss: 0.0681\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0651 - val_loss: 0.0682\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0651 - val_loss: 0.0680\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0651 - val_loss: 0.0681\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0650 - val_loss: 0.0679\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0649 - val_loss: 0.0678\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0648 - val_loss: 0.0679\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0648 - val_loss: 0.0678\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0648 - val_loss: 0.0678\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0648 - val_loss: 0.0676\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0647 - val_loss: 0.0676\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0646 - val_loss: 0.0676\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0646 - val_loss: 0.0673\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0646 - val_loss: 0.0673\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0645 - val_loss: 0.0673\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0645 - val_loss: 0.0673\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0644 - val_loss: 0.0671\n",
      "Epoch 431/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0644 - val_loss: 0.0671\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0644 - val_loss: 0.0669\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0642 - val_loss: 0.0669\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0642 - val_loss: 0.0667\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0667\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0640 - val_loss: 0.0666\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0640 - val_loss: 0.0666\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0639 - val_loss: 0.0665\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0639 - val_loss: 0.0664\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 3s 44ms/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 0.0637 - val_loss: 0.0663\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0638 - val_loss: 0.0665\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0637 - val_loss: 0.0660\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0635 - val_loss: 0.0661\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0634 - val_loss: 0.0658\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0631 - val_loss: 0.0656\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0629 - val_loss: 0.0654\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0628 - val_loss: 0.0653\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0626 - val_loss: 0.0651\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0625 - val_loss: 0.0650\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0623 - val_loss: 0.0650\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0621 - val_loss: 0.0647\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 3s 44ms/step - loss: 0.0619 - val_loss: 0.0645\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0617 - val_loss: 0.0643\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0615 - val_loss: 0.0641\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0612 - val_loss: 0.0643\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0611 - val_loss: 0.0637\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0608 - val_loss: 0.0636\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.0605 - val_loss: 0.0635\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.0604 - val_loss: 0.0633\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0601 - val_loss: 0.0630\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0601 - val_loss: 0.0630\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0599 - val_loss: 0.0629\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0599 - val_loss: 0.0626\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0597 - val_loss: 0.0629\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0598 - val_loss: 0.0642\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0607 - val_loss: 0.0646\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0620 - val_loss: 0.0713\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0678 - val_loss: 0.0750\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0706 - val_loss: 0.0750\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0699 - val_loss: 0.0749\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0701 - val_loss: 0.0734\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0690 - val_loss: 0.0736\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0690 - val_loss: 0.0729\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 0.0682 - val_loss: 0.0720\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0680 - val_loss: 0.0717\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0679 - val_loss: 0.0714\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0676 - val_loss: 0.0712\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0674 - val_loss: 0.0714\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0674 - val_loss: 0.0713\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0673 - val_loss: 0.0709\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0671 - val_loss: 0.0709\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 3s 44ms/step - loss: 0.0669 - val_loss: 0.0710\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0669 - val_loss: 0.0707\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0668 - val_loss: 0.0709\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0667 - val_loss: 0.0712\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0672 - val_loss: 0.0716\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0671 - val_loss: 0.0721\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 0.0677 - val_loss: 0.0734\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0689 - val_loss: 0.0715\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0672 - val_loss: 0.0723\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.0678 - val_loss: 0.0726\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.0683 - val_loss: 0.0716\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 5s 58ms/step - loss: 0.0670 - val_loss: 0.0724\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0674 - val_loss: 0.0710\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0670 - val_loss: 0.0712\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0665 - val_loss: 0.0710\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0668 - val_loss: 0.0701\n",
      "Running LSTM experiments with T=1600\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 4000, 100)         40800     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4000, 5)           505       \n",
      "=================================================================\n",
      "Total params: 41,305\n",
      "Trainable params: 41,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.1110 - val_loss: 0.1064\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.1033 - val_loss: 0.0997\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0968 - val_loss: 0.0939\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0912 - val_loss: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0868 - val_loss: 0.0870\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0853 - val_loss: 0.0882\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0867 - val_loss: 0.0879\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0861 - val_loss: 0.0866\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0850 - val_loss: 0.0863\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0848 - val_loss: 0.0864\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0849 - val_loss: 0.0866\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0850 - val_loss: 0.0866\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 14s 180ms/step - loss: 0.0849 - val_loss: 0.0864\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0847 - val_loss: 0.0863\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.0845 - val_loss: 0.0862\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0844 - val_loss: 0.0861\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.0844 - val_loss: 0.0861\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0845 - val_loss: 0.0861\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0844 - val_loss: 0.0860\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0844 - val_loss: 0.0859\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 10s 130ms/step - loss: 0.0843 - val_loss: 0.0858\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 0.0843 - val_loss: 0.0859\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0843 - val_loss: 0.0859\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 12s 149ms/step - loss: 0.0843 - val_loss: 0.0859\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.0843 - val_loss: 0.0859\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0842 - val_loss: 0.0857\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0842 - val_loss: 0.0857\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 14s 169ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0841 - val_loss: 0.0856\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0841 - val_loss: 0.0856\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 12s 149ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 11s 131ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 15s 182ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 13s 168ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 11s 141ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 11s 140ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 20s 244ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 11s 131ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 12s 151ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 7s 88ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 12s 154ms/step - loss: 0.0838 - val_loss: 0.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 14s 176ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 14s 179ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 7s 90ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 11s 144ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.0839 - val_loss: 0.0851\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 13s 169ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 14s 178ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 12s 151ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 14s 171ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 14s 169ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 11s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 14s 175ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 7s 93ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 13s 168ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 13s 167ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 13s 166ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 14s 177ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 14s 169ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 7s 91ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 14s 174ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 10s 130ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 10s 131ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 11s 140ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 11s 140ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 15s 184ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 13s 156ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 8s 94ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 7s 91ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 11s 140ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 20s 248ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0837 - val_loss: 0.0851\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 14s 172ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 12s 154ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0835 - val_loss: 0.0847\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0833 - val_loss: 0.0841\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0844 - val_loss: 0.0859\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0847 - val_loss: 0.0854\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 0.0842 - val_loss: 0.0860\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0842 - val_loss: 0.0857\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0841 - val_loss: 0.0854\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0840 - val_loss: 0.0854\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 14s 177ms/step - loss: 0.0838 - val_loss: 0.0853\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0838 - val_loss: 0.0853\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 7s 90ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 8s 94ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 13s 157ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 13s 168ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 13s 166ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 7s 92ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 7s 90ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 15s 181ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 15s 182ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 7s 87ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 7s 89ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 14s 176ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 16s 196ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 16s 203ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 13s 169ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 13s 156ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 16s 197ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 13s 167ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 15s 183ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.0837 - val_loss: 0.0851\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 13s 166ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 14s 181ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 13s 157ms/step - loss: 0.0838 - val_loss: 0.0850\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 13s 156ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 13s 166ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 10s 131ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 13s 164ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 13s 164ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0836 - val_loss: 0.0849\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0835 - val_loss: 0.0849\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0835 - val_loss: 0.0848\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 12s 154ms/step - loss: 0.0835 - val_loss: 0.0848\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.0835 - val_loss: 0.0847\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0834 - val_loss: 0.0847\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0834 - val_loss: 0.0848\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0835 - val_loss: 0.0847\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0835 - val_loss: 0.0846\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0835 - val_loss: 0.0846\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0834 - val_loss: 0.0845\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0832 - val_loss: 0.0842\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0832 - val_loss: 0.0844\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0831 - val_loss: 0.0986\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.0928 - val_loss: 0.0868\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0850 - val_loss: 0.0865\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.0846 - val_loss: 0.0863\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.0844 - val_loss: 0.0862\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0844 - val_loss: 0.0863\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.0845 - val_loss: 0.0863\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0845 - val_loss: 0.0861\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 0.0844 - val_loss: 0.0860\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 14s 174ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 14s 171ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 14s 171ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.0842 - val_loss: 0.0860\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.0842 - val_loss: 0.0859\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0842 - val_loss: 0.0859\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 11s 141ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 16s 197ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.0841 - val_loss: 0.0858\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 12s 149ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0841 - val_loss: 0.0857\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0841 - val_loss: 0.0856\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 10s 131ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 15s 182ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 14s 175ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 11s 141ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 7s 89ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0839 - val_loss: 0.0854\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 14s 179ms/step - loss: 0.0839 - val_loss: 0.0853\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 13s 169ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 15s 182ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 8s 94ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 14s 170ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 8s 94ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 11s 140ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 13s 166ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 97ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 14s 177ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 10s 131ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 12s 155ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 11s 139ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.0838 - val_loss: 0.0851\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.0838 - val_loss: 0.0851\n"
     ]
    }
   ],
   "source": [
    "M = []\n",
    "MT = [25, 100, 400, 1600]\n",
    "ME = [500, 500, 500, 500]\n",
    "for T, epochs in zip(MT, ME):\n",
    "    print(\"Running LSTM experiments with T=%d\" % T)\n",
    "    M.append(main.run(factory=main.make_lstm, T=T, epochs=epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM took 0.352852 sec/epoch on T=25\n",
      "LSTM took 1.234265 sec/epoch on T=100\n",
      "LSTM took 3.744452 sec/epoch on T=400\n",
      "LSTM took 10.741795 sec/epoch on T=1600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 482.4x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figname = os.path.join(os.path.abspath(\"\"), \"../figures\", \"capacity.pdf\")\n",
    "\n",
    "plt.figure(figsize=(6.7, 4))\n",
    "plt.title(\"Memory Capacity of Recurrent Architectures\", fontsize=14)\n",
    "for name, R, T, C in (\n",
    "        ('LMU-0', L0, LT0, sns.color_palette(\"Blues\", len(L0)+2)[2:]),\n",
    "        ('LSTM', M, MT, sns.color_palette(\"Reds\", len(M)+1)[1:]),\n",
    "        ):\n",
    "    for r, t, c in zip(R, T, C):\n",
    "        n_outputs = len(r['mses'])\n",
    "        x, y = r['delays'], r['mses']\n",
    "        plt.plot(x, y, c=c, label='%s (T=%d)' % (name, t))\n",
    "        plt.scatter(x, y, c=c, s=4)\n",
    "        if r['time'] is not None:\n",
    "            print(\"%s took %f sec/epoch on T=%d\" % (\n",
    "                name, r['time'], t))\n",
    "plt.xlabel(\"Delay Length (# Time-steps)\", fontsize=14)\n",
    "plt.ylabel(\"Test MSE\", fontsize=14)\n",
    "plt.legend(loc='upper right', framealpha=0)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(0.5, plt.xlim()[1])\n",
    "\n",
    "plt.savefig(figname, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
